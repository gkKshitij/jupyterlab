{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 100\n",
    "learning_rate = 0.01\n",
    " \n",
    "def predict(X, y, coef):\n",
    "    '''\n",
    "    Activation function: w0 + w1*x1 + w2*x2 + ... + wn*xn\n",
    "    '''\n",
    "    output = np.dot(X, coef[1:]) + coef[0]\n",
    "    '''\n",
    "    Unit Step function: Predict 1 if output >= 0 else 0\n",
    "    '''\n",
    "    return np.where(output >= 0.0, 1, 0)\n",
    "     \n",
    "def fit(X, y):\n",
    "        rgen = np.random.RandomState(1)\n",
    "        coef_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        for _ in range(n_iterations):\n",
    "            for xi, expected_value in zip(X, y):\n",
    "                predicted_value = predict(xi, target, coef_)\n",
    "        \n",
    "                coef_[1:] += learning_rate * (expected_value - predicted_value) * xi\n",
    "                coef_[0] += learning_rate * (expected_value - predicted_value) * 1\n",
    "        return coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPerceptron(object):\n",
    "     \n",
    "    def __init__(self, n_iterations=100, random_state=1, learning_rate=0.01):\n",
    "        self.n_iterations = n_iterations\n",
    "        self.random_state = random_state\n",
    "        self.learning_rate = learning_rate\n",
    " \n",
    "    '''\n",
    "    Stochastic Gradient Descent \n",
    "     \n",
    "    1. Weights are updated based on each training examples.\n",
    "    2. Learning of weights can continue for multiple iterations\n",
    "    3. Learning rate needs to be defined\n",
    "    '''\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.coef_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        for _ in range(self.n_iterations):\n",
    "            for xi, expected_value in zip(X, y):\n",
    "                predicted_value = self.predict(xi)\n",
    "                self.coef_[1:] += self.learning_rate * (expected_value - predicted_value) * xi\n",
    "                self.coef_[0] += self.learning_rate * (expected_value - predicted_value) * 1\n",
    "     \n",
    "    '''\n",
    "    Activation function calculates the value of weighted sum of input value\n",
    "    '''\n",
    "    def activation(self, X):\n",
    "            return np.dot(X, self.coef_[1:]) + self.coef_[0]\n",
    "     \n",
    "    '''\n",
    "    Prediction is made on the basis of unit step function\n",
    "    '''\n",
    "    def predict(self, X):\n",
    "        output = self.activation(X) \n",
    "        return np.where(output >= 0.0, 1, 0)\n",
    "     \n",
    "    '''\n",
    "    Model score is calculated based on comparison of \n",
    "    expected value and predicted value\n",
    "    '''\n",
    "    def score(self, X, y):\n",
    "        misclassified_data_count = 0\n",
    "        for xi, target in zip(X, y):\n",
    "            output = self.predict(xi)\n",
    "            if(target != output):\n",
    "                misclassified_data_count += 1\n",
    "        total_data_count = len(X)\n",
    "        self.score_ = (total_data_count - misclassified_data_count)/total_data_count\n",
    "        return self.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-111083a72eeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Load the data set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_breast_cancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load the data set\n",
    "#\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "#\n",
    "# Create training and test split\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "#\n",
    "# Instantiate CustomPerceptron\n",
    "#\n",
    "prcptrn = CustomPerceptron()\n",
    "#\n",
    "# Fit the model\n",
    "#\n",
    "prcptrn.fit(X_train, y_train)\n",
    "#\n",
    "# Score the model\n",
    "#\n",
    "prcptrn.score(X_test, y_test), prcptrn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
