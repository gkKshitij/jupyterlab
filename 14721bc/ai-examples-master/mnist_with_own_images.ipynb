{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to format which CNN expects (batch, height, width, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load images to features and labels\n",
    "def load_images_to_data(image_label, image_directory, features_data, label_data):\n",
    "    list_of_files = os.listdir(image_directory)\n",
    "    for file in list_of_files:\n",
    "        image_file_name = os.path.join(image_directory, file)\n",
    "        if \".png\" in image_file_name:\n",
    "            img = Image.open(image_file_name).convert(\"L\")\n",
    "            img = np.resize(img, (28,28,1))\n",
    "            im2arr = np.array(img)\n",
    "            im2arr = im2arr.reshape(1,28,28,1)\n",
    "            features_data = np.append(features_data, im2arr, axis=0)\n",
    "            label_data = np.append(label_data, [image_label], axis=0)\n",
    "    return features_data, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your own images to training and test data\n",
    "X_train, y_train = load_images_to_data('1', 'data/mnist_data/train/1', X_train, y_train)\n",
    "X_test, y_test = load_images_to_data('1', 'data/mnist_data/validation/1', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train/=255\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode\n",
    "number_of_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "301/301 [==============================] - 15s 49ms/step - loss: 0.4830 - accuracy: 0.8439 - val_loss: 0.0813 - val_accuracy: 0.9743\n",
      "Epoch 2/7\n",
      "301/301 [==============================] - 14s 48ms/step - loss: 0.1538 - accuracy: 0.9529 - val_loss: 0.0535 - val_accuracy: 0.9836\n",
      "Epoch 3/7\n",
      "301/301 [==============================] - 14s 48ms/step - loss: 0.1164 - accuracy: 0.9650 - val_loss: 0.0406 - val_accuracy: 0.9870\n",
      "Epoch 4/7\n",
      "301/301 [==============================] - 14s 48ms/step - loss: 0.0993 - accuracy: 0.9706 - val_loss: 0.0375 - val_accuracy: 0.9878\n",
      "Epoch 5/7\n",
      "301/301 [==============================] - 14s 48ms/step - loss: 0.0905 - accuracy: 0.9727 - val_loss: 0.0312 - val_accuracy: 0.9899\n",
      "Epoch 6/7\n",
      "301/301 [==============================] - 14s 48ms/step - loss: 0.0812 - accuracy: 0.9754 - val_loss: 0.0284 - val_accuracy: 0.9902\n",
      "Epoch 7/7\n",
      "301/301 [==============================] - 14s 47ms/step - loss: 0.0742 - accuracy: 0.9777 - val_loss: 0.0265 - val_accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2648154fac0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=7, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# model.save('models/mnistCNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(Test loss & Test Accuracy): \n",
      "[0.02703550534894785, 0.9917016596680663]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('data/mnist_data/validation/1/1_2.png').convert(\"L\")\n",
    "img = np.resize(img, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
