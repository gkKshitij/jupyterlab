{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    "              'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "              'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "              'admitted': [1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "              }\n",
    "df = pd.DataFrame(candidates,columns= ['gmat', 'gpa','work_experience','admitted'])\n",
    "#print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['gmat', 'gpa','work_experience']]\n",
    "y = df['admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.92,random_state=0)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "\n",
    "logistic_regression= LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "y_pred=logistic_regression.predict(X_test)\n",
    "\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=0.0.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e71d0236b6a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\INSTALLS\\anaconda\\envs\\virtualenv1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1345\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\INSTALLS\\anaconda\\envs\\virtualenv1\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\INSTALLS\\anaconda\\envs\\virtualenv1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\INSTALLS\\anaconda\\envs\\virtualenv1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32mD:\\INSTALLS\\anaconda\\envs\\virtualenv1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\INSTALLS\\anaconda\\envs\\virtualenv1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    614\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=0.0.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "xx=0\n",
    "accura=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 0.01 and Accuracy: 1.0\n",
      "sample size: 0.02 and Accuracy: 1.0\n",
      "sample size: 0.03 and Accuracy: 0.5\n",
      "sample size: 0.04 and Accuracy: 0.5\n",
      "sample size: 0.05 and Accuracy: 0.5\n",
      "sample size: 0.06 and Accuracy: 0.6666666666666666\n",
      "sample size: 0.07 and Accuracy: 0.6666666666666666\n",
      "sample size: 0.08 and Accuracy: 0.5\n",
      "sample size: 0.09 and Accuracy: 0.5\n",
      "sample size: 0.1 and Accuracy: 0.5\n",
      "sample size: 0.11 and Accuracy: 0.6\n",
      "sample size: 0.12 and Accuracy: 0.6\n",
      "sample size: 0.13 and Accuracy: 0.6666666666666666\n",
      "sample size: 0.14 and Accuracy: 0.6666666666666666\n",
      "sample size: 0.15 and Accuracy: 0.6666666666666666\n",
      "sample size: 0.16 and Accuracy: 0.7142857142857143\n",
      "sample size: 0.17 and Accuracy: 0.7142857142857143\n",
      "sample size: 0.18 and Accuracy: 0.75\n",
      "sample size: 0.19 and Accuracy: 0.75\n",
      "sample size: 0.2 and Accuracy: 0.75\n",
      "sample size: 0.21 and Accuracy: 0.7777777777777778\n",
      "sample size: 0.22 and Accuracy: 0.7777777777777778\n",
      "sample size: 0.23 and Accuracy: 0.8\n",
      "sample size: 0.24 and Accuracy: 0.8\n",
      "sample size: 0.25 and Accuracy: 0.8\n",
      "sample size: 0.26 and Accuracy: 0.8181818181818182\n",
      "sample size: 0.27 and Accuracy: 0.8181818181818182\n",
      "sample size: 0.28 and Accuracy: 0.8333333333333334\n",
      "sample size: 0.29 and Accuracy: 0.8333333333333334\n",
      "sample size: 0.3 and Accuracy: 0.8333333333333334\n",
      "sample size: 0.31 and Accuracy: 0.8461538461538461\n",
      "sample size: 0.32 and Accuracy: 0.8461538461538461\n",
      "sample size: 0.33 and Accuracy: 0.7857142857142857\n",
      "sample size: 0.34 and Accuracy: 0.7857142857142857\n",
      "sample size: 0.35 and Accuracy: 0.7857142857142857\n",
      "sample size: 0.36 and Accuracy: 0.8\n",
      "sample size: 0.37 and Accuracy: 0.8\n",
      "sample size: 0.38 and Accuracy: 0.8125\n",
      "sample size: 0.39 and Accuracy: 0.8125\n",
      "sample size: 0.4 and Accuracy: 0.8125\n",
      "sample size: 0.41 and Accuracy: 0.8235294117647058\n",
      "sample size: 0.42 and Accuracy: 0.8235294117647058\n",
      "sample size: 0.43 and Accuracy: 0.8333333333333334\n",
      "sample size: 0.44 and Accuracy: 0.8333333333333334\n",
      "sample size: 0.45 and Accuracy: 0.8333333333333334\n",
      "sample size: 0.46 and Accuracy: 0.8421052631578947\n",
      "sample size: 0.47 and Accuracy: 0.8421052631578947\n",
      "sample size: 0.48 and Accuracy: 0.85\n",
      "sample size: 0.49 and Accuracy: 0.85\n",
      "sample size: 0.5 and Accuracy: 0.85\n",
      "sample size: 0.51 and Accuracy: 0.8095238095238095\n",
      "sample size: 0.52 and Accuracy: 0.8095238095238095\n",
      "sample size: 0.53 and Accuracy: 0.8181818181818182\n",
      "sample size: 0.54 and Accuracy: 0.8181818181818182\n",
      "sample size: 0.55 and Accuracy: 0.8181818181818182\n",
      "sample size: 0.56 and Accuracy: 0.8260869565217391\n",
      "sample size: 0.57 and Accuracy: 0.8260869565217391\n",
      "sample size: 0.58 and Accuracy: 0.8333333333333334\n",
      "sample size: 0.59 and Accuracy: 0.8333333333333334\n",
      "sample size: 0.6 and Accuracy: 0.8333333333333334\n",
      "sample size: 0.61 and Accuracy: 0.84\n",
      "sample size: 0.62 and Accuracy: 0.84\n",
      "sample size: 0.63 and Accuracy: 0.8461538461538461\n",
      "sample size: 0.64 and Accuracy: 0.8461538461538461\n",
      "sample size: 0.65 and Accuracy: 0.8461538461538461\n",
      "sample size: 0.66 and Accuracy: 0.8518518518518519\n",
      "sample size: 0.67 and Accuracy: 0.8518518518518519\n",
      "sample size: 0.68 and Accuracy: 0.8571428571428571\n",
      "sample size: 0.69 and Accuracy: 0.8571428571428571\n",
      "sample size: 0.7 and Accuracy: 0.8571428571428571\n",
      "sample size: 0.71 and Accuracy: 0.6206896551724138\n",
      "sample size: 0.72 and Accuracy: 0.6206896551724138\n",
      "sample size: 0.73 and Accuracy: 0.6333333333333333\n",
      "sample size: 0.74 and Accuracy: 0.6333333333333333\n",
      "sample size: 0.75 and Accuracy: 0.6333333333333333\n",
      "sample size: 0.76 and Accuracy: 0.6451612903225806\n",
      "sample size: 0.77 and Accuracy: 0.6451612903225806\n",
      "sample size: 0.78 and Accuracy: 0.65625\n",
      "sample size: 0.79 and Accuracy: 0.65625\n",
      "sample size: 0.8 and Accuracy: 0.65625\n",
      "sample size: 0.81 and Accuracy: 0.6666666666666666\n",
      "sample size: 0.82 and Accuracy: 0.6666666666666666\n",
      "sample size: 0.83 and Accuracy: 0.6764705882352942\n",
      "sample size: 0.84 and Accuracy: 0.6764705882352942\n",
      "sample size: 0.85 and Accuracy: 0.6764705882352942\n",
      "sample size: 0.86 and Accuracy: 0.6857142857142857\n",
      "sample size: 0.87 and Accuracy: 0.6857142857142857\n",
      "sample size: 0.88 and Accuracy: 0.6944444444444444\n",
      "sample size: 0.89 and Accuracy: 0.6944444444444444\n",
      "sample size: 0.9 and Accuracy: 0.6944444444444444\n",
      "sample size: 0.91 and Accuracy: 0.8108108108108109\n",
      "sample size: 0.92 and Accuracy: 0.8108108108108109\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5d52190e8f77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mconfusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Actual'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predicted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\INSTALLS\\anaconda\\envs\\virtualenv1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1372\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0;32m   1373\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "for i in range(1,100):\n",
    "    j=i/100\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=j,random_state=0)\n",
    "    logistic_regression= LogisticRegression()\n",
    "    logistic_regression.fit(X_train,y_train)\n",
    "    y_pred=logistic_regression.predict(X_test)\n",
    "    confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    #sn.heatmap(confusion_matrix, annot=True)\n",
    "    print(f\"sample size: {j} and Accuracy: {metrics.accuracy_score(y_test, y_pred)}\")\n",
    "    xx=metrics.accuracy_score(y_test, y_pred)\n",
    "    accura.append(xx)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1\n",
       "0    1\n",
       "Name: admitted, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-92ef5540edc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maccura\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Largest element is:{accura[-1]} at index {accura[j]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not float"
     ]
    }
   ],
   "source": [
    "accura.sort() \n",
    "print(f\"Largest element is:{accura[-1]} at index {accura[j]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.7142857142857143,\n",
       " 0.7142857142857143,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.7777777777777778,\n",
       " 0.7777777777777778,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.8181818181818182,\n",
       " 0.8181818181818182,\n",
       " 0.8333333333333334,\n",
       " 0.8333333333333334,\n",
       " 0.8333333333333334,\n",
       " 0.8461538461538461,\n",
       " 0.8461538461538461,\n",
       " 0.7857142857142857,\n",
       " 0.7857142857142857,\n",
       " 0.7857142857142857,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.8125,\n",
       " 0.8125,\n",
       " 0.8125,\n",
       " 0.8235294117647058,\n",
       " 0.8235294117647058,\n",
       " 0.8333333333333334,\n",
       " 0.8333333333333334,\n",
       " 0.8333333333333334,\n",
       " 0.8421052631578947,\n",
       " 0.8421052631578947,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.8095238095238095,\n",
       " 0.8095238095238095,\n",
       " 0.8181818181818182,\n",
       " 0.8181818181818182,\n",
       " 0.8181818181818182,\n",
       " 0.8260869565217391,\n",
       " 0.8260869565217391,\n",
       " 0.8333333333333334,\n",
       " 0.8333333333333334,\n",
       " 0.8333333333333334,\n",
       " 0.84,\n",
       " 0.84,\n",
       " 0.8461538461538461,\n",
       " 0.8461538461538461,\n",
       " 0.8461538461538461,\n",
       " 0.8518518518518519,\n",
       " 0.8518518518518519,\n",
       " 0.8571428571428571,\n",
       " 0.8571428571428571,\n",
       " 0.8571428571428571,\n",
       " 0.6206896551724138,\n",
       " 0.6206896551724138,\n",
       " 0.6333333333333333,\n",
       " 0.6333333333333333,\n",
       " 0.6333333333333333,\n",
       " 0.6451612903225806,\n",
       " 0.6451612903225806,\n",
       " 0.65625,\n",
       " 0.65625,\n",
       " 0.65625,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6764705882352942,\n",
       " 0.6764705882352942,\n",
       " 0.6764705882352942,\n",
       " 0.6857142857142857,\n",
       " 0.6857142857142857,\n",
       " 0.6944444444444444,\n",
       " 0.6944444444444444,\n",
       " 0.6944444444444444,\n",
       " 0.8108108108108109,\n",
       " 0.8108108108108109]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
